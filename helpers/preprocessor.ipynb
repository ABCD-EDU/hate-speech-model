{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import preprocessor as p\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from collections import defaultdict\n",
    "import contractions\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "# pd.set_option('display.max_rows', 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets_text(df, task_name):\n",
    "\n",
    "    # Clean text with twitter-preprocessor\n",
    "    clean = []\n",
    "    for i, v in enumerate(df['text']):\n",
    "        clean.append(p.clean(v))\n",
    "    df[\"text\"] = clean\n",
    "\n",
    "    # Convert to lower case\n",
    "    df[\"text\"] = [entry.lower() for entry in df[\"text\"]]\n",
    "\n",
    "    # Expand Contractions\n",
    "\n",
    "\n",
    "    def expand_contractions(s):\n",
    "        expanded = []\n",
    "        for word in s.split():\n",
    "            expanded.append(contractions.fix(word))\n",
    "        return(' '.join(expanded))\n",
    "\n",
    "\n",
    "    df[\"text\"] = [expand_contractions(entry) for entry in df['text']]\n",
    "\n",
    "    # Remove punctuation marks\n",
    "    df[\"text\"] = [entry.translate(str.maketrans(\n",
    "        '', '', string.punctuation)) for entry in df[\"text\"]]\n",
    "\n",
    "    # Tokenization\n",
    "    # df['text']= [word_tokenize(entry) for entry in df['text']]\n",
    "    df.to_csv(f'../res/preprocessed/{task_name}/{task_name}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLEAN task 1, 2 and 3 texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_df = pd.read_csv('../res/raw/subtask2.csv')\n",
    "task_df.drop([\"tweet_id\",  \"ID\", \"task2\"], axis=1, inplace=True)\n",
    "\n",
    "# Apply one hot encoding\n",
    "task_df = task_df.join(pd.get_dummies(task_df['task1']))\n",
    "task_df = task_df.dropna().drop(columns=['task1'])\n",
    "task1_df = task_df\n",
    "clean_tweets_text(task_df, 'task1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_df = pd.read_csv('../res/raw/subtask2.csv')\n",
    "task_df.drop([\"tweet_id\",  \"ID\", \"task1\"], axis=1, inplace=True)\n",
    "\n",
    "# Apply one hot encoding\n",
    "task_df = task_df.join(pd.get_dummies(task_df['task2']))\n",
    "task_df = task_df.dropna().drop(columns=['task2'])\n",
    "task2_df = task_df\n",
    "clean_tweets_text(task_df, 'task2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../res/raw/raw_task3.csv')\n",
    "df = df.rename(columns={'tweet_text':'text'})\n",
    "clean_tweets_text(df, 'task3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine task1 and task2 one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.merge(task1_df, task2_df, left_index=True, right_index=True)\n",
    "task2_df_temp = task2_df.drop(columns=['text'])\n",
    "df = pd.concat([task1_df, task2_df_temp], axis=1)\n",
    "df.to_csv('../res/preprocessed/task1_2/task1_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cce0fa9ca151fc59ef80132faf12b1d36d7815ac2454a49ae42a11694118af52"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ai-ds-test2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
